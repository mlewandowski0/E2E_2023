{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "DOWNLOAD_PATH = 'data/mnist'\n",
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_TEST = 1000\n",
    "\n",
    "transform_mnist = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(DOWNLOAD_PATH, train=True, download=True,\n",
    "                                       transform=transform_mnist)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(DOWNLOAD_PATH, train=False, download=True,\n",
    "                                      transform=transform_mnist)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE_TEST, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import torch.nn.functional as  F\n",
    "\n",
    "def train_epoch(model, optimizer, data_loader, loss_history):\n",
    "    total_samples = len(data_loader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = F.log_softmax(model(data), dim=1)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(total_samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_loader)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(loss.item()))\n",
    "            loss_history.append(loss.item())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, loss_history):\n",
    "    model.eval()\n",
    "\n",
    "    total_samples = len(data_loader.dataset)\n",
    "    correct_samples = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = F.log_softmax(model(data), dim=1)\n",
    "            loss = F.nll_loss(output, target, reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct_samples += pred.eq(target).sum()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    loss_history.append(avg_loss)\n",
    "    print('\\nAverage test loss: ' + '{:.4f}'.format(avg_loss) +\n",
    "          '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\n",
    "          '{:5}'.format(total_samples) + ' (' +\n",
    "          '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/60000 (  0%)]  Loss: 2.4446\n",
      "[10000/60000 ( 17%)]  Loss: 0.2114\n",
      "[20000/60000 ( 33%)]  Loss: 0.1262\n",
      "[30000/60000 ( 50%)]  Loss: 0.2215\n",
      "[40000/60000 ( 67%)]  Loss: 0.1623\n",
      "[50000/60000 ( 83%)]  Loss: 0.4492\n",
      "\n",
      "Average test loss: 0.1708  Accuracy: 9472/10000 (94.72%)\n",
      "\n",
      "Epoch: 2\n",
      "[    0/60000 (  0%)]  Loss: 0.2567\n",
      "[10000/60000 ( 17%)]  Loss: 0.2651\n",
      "[20000/60000 ( 33%)]  Loss: 0.2236\n",
      "[30000/60000 ( 50%)]  Loss: 0.0845\n",
      "[40000/60000 ( 67%)]  Loss: 0.1750\n",
      "[50000/60000 ( 83%)]  Loss: 0.2925\n",
      "\n",
      "Average test loss: 0.1547  Accuracy: 9526/10000 (95.26%)\n",
      "\n",
      "Epoch: 3\n",
      "[    0/60000 (  0%)]  Loss: 0.1240\n",
      "[10000/60000 ( 17%)]  Loss: 0.0974\n",
      "[20000/60000 ( 33%)]  Loss: 0.0718\n",
      "[30000/60000 ( 50%)]  Loss: 0.2449\n",
      "[40000/60000 ( 67%)]  Loss: 0.0667\n",
      "[50000/60000 ( 83%)]  Loss: 0.1239\n",
      "\n",
      "Average test loss: 0.1118  Accuracy: 9653/10000 (96.53%)\n",
      "\n",
      "Epoch: 4\n",
      "[    0/60000 (  0%)]  Loss: 0.0578\n",
      "[10000/60000 ( 17%)]  Loss: 0.0998\n",
      "[20000/60000 ( 33%)]  Loss: 0.0712\n",
      "[30000/60000 ( 50%)]  Loss: 0.1402\n",
      "[40000/60000 ( 67%)]  Loss: 0.0464\n",
      "[50000/60000 ( 83%)]  Loss: 0.1293\n",
      "\n",
      "Average test loss: 0.1105  Accuracy: 9653/10000 (96.53%)\n",
      "\n",
      "Epoch: 5\n",
      "[    0/60000 (  0%)]  Loss: 0.0677\n",
      "[10000/60000 ( 17%)]  Loss: 0.1097\n",
      "[20000/60000 ( 33%)]  Loss: 0.0539\n",
      "[30000/60000 ( 50%)]  Loss: 0.0222\n",
      "[40000/60000 ( 67%)]  Loss: 0.0841\n",
      "[50000/60000 ( 83%)]  Loss: 0.0841\n",
      "\n",
      "Average test loss: 0.0832  Accuracy: 9739/10000 (97.39%)\n",
      "\n",
      "Epoch: 6\n",
      "[    0/60000 (  0%)]  Loss: 0.0735\n",
      "[10000/60000 ( 17%)]  Loss: 0.0664\n",
      "[20000/60000 ( 33%)]  Loss: 0.1026\n",
      "[30000/60000 ( 50%)]  Loss: 0.0378\n",
      "[40000/60000 ( 67%)]  Loss: 0.0516\n",
      "[50000/60000 ( 83%)]  Loss: 0.0645\n",
      "\n",
      "Average test loss: 0.0849  Accuracy: 9743/10000 (97.43%)\n",
      "\n",
      "Epoch: 7\n",
      "[    0/60000 (  0%)]  Loss: 0.0139\n",
      "[10000/60000 ( 17%)]  Loss: 0.0643\n",
      "[20000/60000 ( 33%)]  Loss: 0.1247\n",
      "[30000/60000 ( 50%)]  Loss: 0.0393\n",
      "[40000/60000 ( 67%)]  Loss: 0.0731\n",
      "[50000/60000 ( 83%)]  Loss: 0.1177\n",
      "\n",
      "Average test loss: 0.1105  Accuracy: 9636/10000 (96.36%)\n",
      "\n",
      "Epoch: 8\n",
      "[    0/60000 (  0%)]  Loss: 0.1485\n",
      "[10000/60000 ( 17%)]  Loss: 0.0798\n",
      "[20000/60000 ( 33%)]  Loss: 0.1637\n",
      "[30000/60000 ( 50%)]  Loss: 0.1368\n",
      "[40000/60000 ( 67%)]  Loss: 0.0681\n",
      "[50000/60000 ( 83%)]  Loss: 0.1070\n",
      "\n",
      "Average test loss: 0.0866  Accuracy: 9747/10000 (97.47%)\n",
      "\n",
      "Epoch: 9\n",
      "[    0/60000 (  0%)]  Loss: 0.0512\n",
      "[10000/60000 ( 17%)]  Loss: 0.0967\n",
      "[20000/60000 ( 33%)]  Loss: 0.0856\n",
      "[30000/60000 ( 50%)]  Loss: 0.1124\n",
      "[40000/60000 ( 67%)]  Loss: 0.0145\n",
      "[50000/60000 ( 83%)]  Loss: 0.0550\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_37204/420506986.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mN_EPOCHS\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Epoch:'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m     \u001B[0mtrain_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_loss_history\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m     \u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_loss_history\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_37204/699261893.py\u001B[0m in \u001B[0;36mtrain_epoch\u001B[0;34m(model, optimizer, data_loader, loss_history)\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_softmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnll_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    486\u001B[0m                 \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    487\u001B[0m             )\n\u001B[0;32m--> 488\u001B[0;31m         torch.autograd.backward(\n\u001B[0m\u001B[1;32m    489\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    490\u001B[0m         )\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     \u001B[0;31m# some Python versions print out the first line of a multi-line function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    196\u001B[0m     \u001B[0;31m# calls in the traceback and some print out the last line\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 197\u001B[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[1;32m    198\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    199\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.optim as optim\n",
    "\n",
    "N_EPOCHS = 25\n",
    "\n",
    "start_time = time.time()\n",
    "model = ViT(image_size=28, patch_size=7, num_classes=10, channels=1, dim=64, depth=6, heads=8, mlp_dim=128)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "train_loss_history, test_loss_history = [], []\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_epoch(model, optimizer, train_loader, train_loss_history)\n",
    "    evaluate(model, test_loader, test_loss_history)\n",
    "\n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.1754]], device='cuda:0', grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vit_pytorch import ViT\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "v = ViT(\n",
    "    image_size = 32,\n",
    "    patch_size = 4,\n",
    "    num_classes = 1,\n",
    "    channels=2,\n",
    "    dim = 64,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 128,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "\n",
    "v = v.to(device)\n",
    "img = torch.randn(1, 2, 32, 32)\n",
    "v(img.to(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Rearrange-1               [-1, 64, 32]               0\n",
      "         LayerNorm-2               [-1, 64, 32]              64\n",
      "            Linear-3               [-1, 64, 64]           2,112\n",
      "         LayerNorm-4               [-1, 64, 64]             128\n",
      "           Dropout-5               [-1, 65, 64]               0\n",
      "         LayerNorm-6               [-1, 65, 64]             128\n",
      "            Linear-7             [-1, 65, 1536]          98,304\n",
      "           Softmax-8            [-1, 8, 65, 65]               0\n",
      "           Dropout-9            [-1, 8, 65, 65]               0\n",
      "           Linear-10               [-1, 65, 64]          32,832\n",
      "          Dropout-11               [-1, 65, 64]               0\n",
      "        Attention-12               [-1, 65, 64]               0\n",
      "          PreNorm-13               [-1, 65, 64]               0\n",
      "        LayerNorm-14               [-1, 65, 64]             128\n",
      "           Linear-15              [-1, 65, 128]           8,320\n",
      "             GELU-16              [-1, 65, 128]               0\n",
      "          Dropout-17              [-1, 65, 128]               0\n",
      "           Linear-18               [-1, 65, 64]           8,256\n",
      "          Dropout-19               [-1, 65, 64]               0\n",
      "      FeedForward-20               [-1, 65, 64]               0\n",
      "          PreNorm-21               [-1, 65, 64]               0\n",
      "        LayerNorm-22               [-1, 65, 64]             128\n",
      "           Linear-23             [-1, 65, 1536]          98,304\n",
      "          Softmax-24            [-1, 8, 65, 65]               0\n",
      "          Dropout-25            [-1, 8, 65, 65]               0\n",
      "           Linear-26               [-1, 65, 64]          32,832\n",
      "          Dropout-27               [-1, 65, 64]               0\n",
      "        Attention-28               [-1, 65, 64]               0\n",
      "          PreNorm-29               [-1, 65, 64]               0\n",
      "        LayerNorm-30               [-1, 65, 64]             128\n",
      "           Linear-31              [-1, 65, 128]           8,320\n",
      "             GELU-32              [-1, 65, 128]               0\n",
      "          Dropout-33              [-1, 65, 128]               0\n",
      "           Linear-34               [-1, 65, 64]           8,256\n",
      "          Dropout-35               [-1, 65, 64]               0\n",
      "      FeedForward-36               [-1, 65, 64]               0\n",
      "          PreNorm-37               [-1, 65, 64]               0\n",
      "        LayerNorm-38               [-1, 65, 64]             128\n",
      "           Linear-39             [-1, 65, 1536]          98,304\n",
      "          Softmax-40            [-1, 8, 65, 65]               0\n",
      "          Dropout-41            [-1, 8, 65, 65]               0\n",
      "           Linear-42               [-1, 65, 64]          32,832\n",
      "          Dropout-43               [-1, 65, 64]               0\n",
      "        Attention-44               [-1, 65, 64]               0\n",
      "          PreNorm-45               [-1, 65, 64]               0\n",
      "        LayerNorm-46               [-1, 65, 64]             128\n",
      "           Linear-47              [-1, 65, 128]           8,320\n",
      "             GELU-48              [-1, 65, 128]               0\n",
      "          Dropout-49              [-1, 65, 128]               0\n",
      "           Linear-50               [-1, 65, 64]           8,256\n",
      "          Dropout-51               [-1, 65, 64]               0\n",
      "      FeedForward-52               [-1, 65, 64]               0\n",
      "          PreNorm-53               [-1, 65, 64]               0\n",
      "        LayerNorm-54               [-1, 65, 64]             128\n",
      "           Linear-55             [-1, 65, 1536]          98,304\n",
      "          Softmax-56            [-1, 8, 65, 65]               0\n",
      "          Dropout-57            [-1, 8, 65, 65]               0\n",
      "           Linear-58               [-1, 65, 64]          32,832\n",
      "          Dropout-59               [-1, 65, 64]               0\n",
      "        Attention-60               [-1, 65, 64]               0\n",
      "          PreNorm-61               [-1, 65, 64]               0\n",
      "        LayerNorm-62               [-1, 65, 64]             128\n",
      "           Linear-63              [-1, 65, 128]           8,320\n",
      "             GELU-64              [-1, 65, 128]               0\n",
      "          Dropout-65              [-1, 65, 128]               0\n",
      "           Linear-66               [-1, 65, 64]           8,256\n",
      "          Dropout-67               [-1, 65, 64]               0\n",
      "      FeedForward-68               [-1, 65, 64]               0\n",
      "          PreNorm-69               [-1, 65, 64]               0\n",
      "        LayerNorm-70               [-1, 65, 64]             128\n",
      "           Linear-71             [-1, 65, 1536]          98,304\n",
      "          Softmax-72            [-1, 8, 65, 65]               0\n",
      "          Dropout-73            [-1, 8, 65, 65]               0\n",
      "           Linear-74               [-1, 65, 64]          32,832\n",
      "          Dropout-75               [-1, 65, 64]               0\n",
      "        Attention-76               [-1, 65, 64]               0\n",
      "          PreNorm-77               [-1, 65, 64]               0\n",
      "        LayerNorm-78               [-1, 65, 64]             128\n",
      "           Linear-79              [-1, 65, 128]           8,320\n",
      "             GELU-80              [-1, 65, 128]               0\n",
      "          Dropout-81              [-1, 65, 128]               0\n",
      "           Linear-82               [-1, 65, 64]           8,256\n",
      "          Dropout-83               [-1, 65, 64]               0\n",
      "      FeedForward-84               [-1, 65, 64]               0\n",
      "          PreNorm-85               [-1, 65, 64]               0\n",
      "        LayerNorm-86               [-1, 65, 64]             128\n",
      "           Linear-87             [-1, 65, 1536]          98,304\n",
      "          Softmax-88            [-1, 8, 65, 65]               0\n",
      "          Dropout-89            [-1, 8, 65, 65]               0\n",
      "           Linear-90               [-1, 65, 64]          32,832\n",
      "          Dropout-91               [-1, 65, 64]               0\n",
      "        Attention-92               [-1, 65, 64]               0\n",
      "          PreNorm-93               [-1, 65, 64]               0\n",
      "        LayerNorm-94               [-1, 65, 64]             128\n",
      "           Linear-95              [-1, 65, 128]           8,320\n",
      "             GELU-96              [-1, 65, 128]               0\n",
      "          Dropout-97              [-1, 65, 128]               0\n",
      "           Linear-98               [-1, 65, 64]           8,256\n",
      "          Dropout-99               [-1, 65, 64]               0\n",
      "     FeedForward-100               [-1, 65, 64]               0\n",
      "         PreNorm-101               [-1, 65, 64]               0\n",
      "     Transformer-102               [-1, 65, 64]               0\n",
      "        Identity-103                   [-1, 64]               0\n",
      "       LayerNorm-104                   [-1, 64]             128\n",
      "          Linear-105                    [-1, 1]              65\n",
      "================================================================\n",
      "Total params: 890,305\n",
      "Trainable params: 890,305\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 10.87\n",
      "Params size (MB): 3.40\n",
      "Estimated Total Size (MB): 14.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(v, (2,32,32))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from vit_pytorch.mobile_vit import MobileViT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
