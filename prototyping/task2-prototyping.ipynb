{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 23:11:53.735076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102 files belonging to 2 classes.\n",
      "ASDASD\n",
      "['dataset/class1/0.npy', 'dataset/class1/20.npy', 'dataset/class1/41.npy', 'dataset/class2/6.npy', 'dataset/class1/15.npy', 'dataset/class2/38.npy', 'dataset/class1/17.npy', 'dataset/class2/43.npy', 'dataset/class1/22.npy', 'dataset/class2/19.npy', 'dataset/class2/39.npy', 'dataset/class2/12.npy', 'dataset/class2/14.npy', 'dataset/class2/46.npy', 'dataset/class2/33.npy', 'dataset/class2/1.npy', 'dataset/class1/26.npy', 'dataset/class1/42.npy', 'dataset/class2/7.npy', 'dataset/class2/16.npy', 'dataset/class2/20.npy', 'dataset/class2/23.npy', 'dataset/class2/9.npy', 'dataset/class1/11.npy', 'dataset/class2/10.npy', 'dataset/class1/40.npy', 'dataset/class2/5.npy', 'dataset/class2/37.npy', 'dataset/class1/46.npy', 'dataset/class1/35.npy', 'dataset/class1/32.npy', 'dataset/class1/9.npy', 'dataset/class2/4.npy', 'dataset/class2/8.npy', 'dataset/class1/45.npy', 'dataset/class1/39.npy', 'dataset/class1/8.npy', 'dataset/class1/3.npy', 'dataset/class1/27.npy', 'dataset/class2/29.npy', 'dataset/class2/36.npy', 'dataset/class2/15.npy', 'dataset/class1/50.npy', 'dataset/class1/4.npy', 'dataset/class2/41.npy', 'dataset/class2/25.npy', 'dataset/class1/28.npy', 'dataset/class1/33.npy', 'dataset/class2/34.npy', 'dataset/class1/14.npy', 'dataset/class1/21.npy', 'dataset/class2/32.npy', 'dataset/class2/35.npy', 'dataset/class1/12.npy', 'dataset/class1/44.npy', 'dataset/class1/37.npy', 'dataset/class1/6.npy', 'dataset/class1/34.npy', 'dataset/class1/48.npy', 'dataset/class2/47.npy', 'dataset/class2/13.npy', 'dataset/class2/2.npy', 'dataset/class2/44.npy', 'dataset/class2/3.npy', 'dataset/class1/23.npy', 'dataset/class1/30.npy', 'dataset/class2/0.npy', 'dataset/class2/30.npy', 'dataset/class2/31.npy', 'dataset/class2/26.npy', 'dataset/class1/49.npy', 'dataset/class1/43.npy', 'dataset/class1/38.npy', 'dataset/class2/21.npy', 'dataset/class2/27.npy', 'dataset/class1/5.npy', 'dataset/class2/11.npy', 'dataset/class1/47.npy', 'dataset/class1/13.npy', 'dataset/class1/19.npy', 'dataset/class1/18.npy', 'dataset/class2/45.npy', 'dataset/class1/16.npy', 'dataset/class1/29.npy', 'dataset/class2/24.npy', 'dataset/class1/24.npy', 'dataset/class2/22.npy', 'dataset/class2/49.npy', 'dataset/class2/17.npy', 'dataset/class1/2.npy', 'dataset/class2/50.npy', 'dataset/class1/7.npy', 'dataset/class2/18.npy', 'dataset/class2/48.npy', 'dataset/class2/42.npy', 'dataset/class2/28.npy', 'dataset/class1/25.npy', 'dataset/class1/31.npy', 'dataset/class1/36.npy', 'dataset/class1/1.npy', 'dataset/class1/10.npy', 'dataset/class2/40.npy']\n",
      "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n",
      "Tensor(\"args_0:0\", shape=(), dtype=string) (125, 125) 3\n",
      "<ParallelMapDataset element_spec=TensorSpec(shape=(5,), dtype=tf.float32, name=None)>\n",
      "<ParallelMapDataset element_spec=TensorSpec(shape=(5,), dtype=tf.float32, name=None)>\n",
      "(32, 5)\n",
      "(32, 5)\n",
      "(32, 5)\n",
      "(6, 5)\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Keras image dataset loading utilities.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "\n",
    "from keras.utils import dataset_utils\n",
    "from keras.utils import image_utils\n",
    "\n",
    "# isort: off\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "\n",
    "\n",
    "ALLOWLIST_FORMATS = (\".bmp\", \".gif\", \".jpeg\", \".jpg\", \".png\", \".npy\")\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    \"keras.utils.image_dataset_from_directory\",\n",
    "    \"keras.preprocessing.image_dataset_from_directory\",\n",
    "    v1=[],\n",
    ")\n",
    "def image_dataset_from_directory(\n",
    "    directory,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"Generates a `tf.data.Dataset` from image files in a directory.\n",
    "\n",
    "    If your directory structure is:\n",
    "\n",
    "    ```\n",
    "    main_directory/\n",
    "    ...class_a/\n",
    "    ......a_image_1.jpg\n",
    "    ......a_image_2.jpg\n",
    "    ...class_b/\n",
    "    ......b_image_1.jpg\n",
    "    ......b_image_2.jpg\n",
    "    ```\n",
    "\n",
    "    Then calling `image_dataset_from_directory(main_directory,\n",
    "    labels='inferred')` will return a `tf.data.Dataset` that yields batches of\n",
    "    images from the subdirectories `class_a` and `class_b`, together with labels\n",
    "    0 and 1 (0 corresponding to `class_a` and 1 corresponding to `class_b`).\n",
    "\n",
    "    Supported image formats: jpeg, png, bmp, gif.\n",
    "    Animated gifs are truncated to the first frame.\n",
    "\n",
    "    Args:\n",
    "      directory: Directory where the data is located.\n",
    "          If `labels` is \"inferred\", it should contain\n",
    "          subdirectories, each containing images for a class.\n",
    "          Otherwise, the directory structure is ignored.\n",
    "      labels: Either \"inferred\"\n",
    "          (labels are generated from the directory structure),\n",
    "          None (no labels),\n",
    "          or a list/tuple of integer labels of the same size as the number of\n",
    "          image files found in the directory. Labels should be sorted according\n",
    "          to the alphanumeric order of the image file paths\n",
    "          (obtained via `os.walk(directory)` in Python).\n",
    "      label_mode: String describing the encoding of `labels`. Options are:\n",
    "          - 'int': means that the labels are encoded as integers\n",
    "              (e.g. for `sparse_categorical_crossentropy` loss).\n",
    "          - 'categorical' means that the labels are\n",
    "              encoded as a categorical vector\n",
    "              (e.g. for `categorical_crossentropy` loss).\n",
    "          - 'binary' means that the labels (there can be only 2)\n",
    "              are encoded as `float32` scalars with values 0 or 1\n",
    "              (e.g. for `binary_crossentropy`).\n",
    "          - None (no labels).\n",
    "      class_names: Only valid if \"labels\" is \"inferred\". This is the explicit\n",
    "          list of class names (must match names of subdirectories). Used\n",
    "          to control the order of the classes\n",
    "          (otherwise alphanumerical order is used).\n",
    "      color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
    "          Whether the images will be converted to\n",
    "          have 1, 3, or 4 channels.\n",
    "      batch_size: Size of the batches of data. Default: 32.\n",
    "        If `None`, the data will not be batched\n",
    "        (the dataset will yield individual samples).\n",
    "      image_size: Size to resize images to after they are read from disk,\n",
    "          specified as `(height, width)`. Defaults to `(256, 256)`.\n",
    "          Since the pipeline processes batches of images that must all have\n",
    "          the same size, this must be provided.\n",
    "      shuffle: Whether to shuffle the data. Default: True.\n",
    "          If set to False, sorts the data in alphanumeric order.\n",
    "      seed: Optional random seed for shuffling and transformations.\n",
    "      validation_split: Optional float between 0 and 1,\n",
    "          fraction of data to reserve for validation.\n",
    "      subset: Subset of the data to return.\n",
    "          One of \"training\", \"validation\" or \"both\".\n",
    "          Only used if `validation_split` is set.\n",
    "          When `subset=\"both\"`, the utility returns a tuple of two datasets\n",
    "          (the training and validation datasets respectively).\n",
    "      interpolation: String, the interpolation method used when resizing images.\n",
    "        Defaults to `bilinear`. Supports `bilinear`, `nearest`, `bicubic`,\n",
    "        `area`, `lanczos3`, `lanczos5`, `gaussian`, `mitchellcubic`.\n",
    "      follow_links: Whether to visit subdirectories pointed to by symlinks.\n",
    "          Defaults to False.\n",
    "      crop_to_aspect_ratio: If True, resize the images without aspect\n",
    "        ratio distortion. When the original aspect ratio differs from the target\n",
    "        aspect ratio, the output image will be cropped so as to return the\n",
    "        largest possible window in the image (of size `image_size`) that matches\n",
    "        the target aspect ratio. By default (`crop_to_aspect_ratio=False`),\n",
    "        aspect ratio may not be preserved.\n",
    "      **kwargs: Legacy keyword arguments.\n",
    "\n",
    "    Returns:\n",
    "      A `tf.data.Dataset` object.\n",
    "        - If `label_mode` is None, it yields `float32` tensors of shape\n",
    "          `(batch_size, image_size[0], image_size[1], num_channels)`,\n",
    "          encoding images (see below for rules regarding `num_channels`).\n",
    "        - Otherwise, it yields a tuple `(images, labels)`, where `images`\n",
    "          has shape `(batch_size, image_size[0], image_size[1], num_channels)`,\n",
    "          and `labels` follows the format described below.\n",
    "\n",
    "    Rules regarding labels format:\n",
    "      - if `label_mode` is `int`, the labels are an `int32` tensor of shape\n",
    "        `(batch_size,)`.\n",
    "      - if `label_mode` is `binary`, the labels are a `float32` tensor of\n",
    "        1s and 0s of shape `(batch_size, 1)`.\n",
    "      - if `label_mode` is `categorical`, the labels are a `float32` tensor\n",
    "        of shape `(batch_size, num_classes)`, representing a one-hot\n",
    "        encoding of the class index.\n",
    "\n",
    "    Rules regarding number of channels in the yielded images:\n",
    "      - if `color_mode` is `grayscale`,\n",
    "        there's 1 channel in the image tensors.\n",
    "      - if `color_mode` is `rgb`,\n",
    "        there are 3 channels in the image tensors.\n",
    "      - if `color_mode` is `rgba`,\n",
    "        there are 4 channels in the image tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    if kwargs:\n",
    "        raise TypeError(f\"Unknown keywords argument(s): {tuple(kwargs.keys())}\")\n",
    "    if labels not in (\"inferred\", None):\n",
    "        if not isinstance(labels, (list, tuple)):\n",
    "            raise ValueError(\n",
    "                \"`labels` argument should be a list/tuple of integer labels, \"\n",
    "                \"of the same size as the number of image files in the target \"\n",
    "                \"directory. If you wish to infer the labels from the \"\n",
    "                \"subdirectory \"\n",
    "                'names in the target directory, pass `labels=\"inferred\"`. '\n",
    "                \"If you wish to get a dataset that only contains images \"\n",
    "                f\"(no labels), pass `labels=None`. Received: labels={labels}\"\n",
    "            )\n",
    "        if class_names:\n",
    "            raise ValueError(\n",
    "                \"You can only pass `class_names` if \"\n",
    "                f'`labels=\"inferred\"`. Received: labels={labels}, and '\n",
    "                f\"class_names={class_names}\"\n",
    "            )\n",
    "    if label_mode not in {\"int\", \"categorical\", \"binary\", None}:\n",
    "        raise ValueError(\n",
    "            '`label_mode` argument must be one of \"int\", '\n",
    "            '\"categorical\", \"binary\", '\n",
    "            f\"or None. Received: label_mode={label_mode}\"\n",
    "        )\n",
    "    if labels is None or label_mode is None:\n",
    "        labels = None\n",
    "        label_mode = None\n",
    "    if color_mode == \"rgb\":\n",
    "        num_channels = 3\n",
    "    elif color_mode == \"rgba\":\n",
    "        num_channels = 4\n",
    "    elif color_mode == \"grayscale\":\n",
    "        num_channels = 1\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            '`color_mode` must be one of {\"rgb\", \"rgba\", \"grayscale\"}. '\n",
    "            f\"Received: color_mode={color_mode}\"\n",
    "        )\n",
    "    \n",
    "    dataset_utils.check_validation_split_arg(\n",
    "        validation_split, subset, shuffle, seed\n",
    "    )\n",
    "\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(1e6)\n",
    "    image_paths, labels, class_names = dataset_utils.index_directory(\n",
    "        directory,\n",
    "        labels,\n",
    "        formats=ALLOWLIST_FORMATS,\n",
    "        class_names=class_names,\n",
    "        shuffle=shuffle,\n",
    "        seed=seed,\n",
    "        follow_links=follow_links,\n",
    "    )\n",
    "\n",
    "    if label_mode == \"binary\" and len(class_names) != 2:\n",
    "        raise ValueError(\n",
    "            'When passing `label_mode=\"binary\"`, there must be exactly 2 '\n",
    "            f\"class_names. Received: class_names={class_names}\"\n",
    "        )\n",
    "\n",
    "    if subset == \"both\":\n",
    "        (\n",
    "            image_paths_train,\n",
    "            labels_train,\n",
    "        ) = dataset_utils.get_training_or_validation_split(\n",
    "            image_paths, labels, validation_split, \"training\"\n",
    "        )\n",
    "        (\n",
    "            image_paths_val,\n",
    "            labels_val,\n",
    "        ) = dataset_utils.get_training_or_validation_split(\n",
    "            image_paths, labels, validation_split, \"validation\"\n",
    "        )\n",
    "        if not image_paths_train:\n",
    "            raise ValueError(\n",
    "                f\"No training images found in directory {directory}. \"\n",
    "                f\"Allowed formats: {ALLOWLIST_FORMATS}\"\n",
    "            )\n",
    "        if not image_paths_val:\n",
    "            raise ValueError(\n",
    "                f\"No validation images found in directory {directory}. \"\n",
    "                f\"Allowed formats: {ALLOWLIST_FORMATS}\"\n",
    "            )\n",
    "        train_dataset = paths_and_labels_to_dataset(\n",
    "            image_paths=image_paths_train,\n",
    "            image_size=image_size,\n",
    "            num_channels=num_channels,\n",
    "            labels=labels_train,\n",
    "            label_mode=label_mode,\n",
    "            num_classes=len(class_names),\n",
    "            interpolation=interpolation,\n",
    "            crop_to_aspect_ratio=crop_to_aspect_ratio,\n",
    "        )\n",
    "        val_dataset = paths_and_labels_to_dataset(\n",
    "            image_paths=image_paths_val,\n",
    "            image_size=image_size,\n",
    "            num_channels=num_channels,\n",
    "            labels=labels_val,\n",
    "            label_mode=label_mode,\n",
    "            num_classes=len(class_names),\n",
    "            interpolation=interpolation,\n",
    "            crop_to_aspect_ratio=crop_to_aspect_ratio,\n",
    "        )\n",
    "        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        if batch_size is not None:\n",
    "            if shuffle:\n",
    "                # Shuffle locally at each iteration\n",
    "                train_dataset = train_dataset.shuffle(\n",
    "                    buffer_size=batch_size * 8, seed=seed\n",
    "                )\n",
    "            train_dataset = train_dataset.batch(batch_size)\n",
    "            val_dataset = val_dataset.batch(batch_size)\n",
    "        else:\n",
    "            if shuffle:\n",
    "                train_dataset = train_dataset.shuffle(\n",
    "                    buffer_size=1024, seed=seed\n",
    "                )\n",
    "\n",
    "        # Users may need to reference `class_names`.\n",
    "        train_dataset.class_names = class_names\n",
    "        val_dataset.class_names = class_names\n",
    "        # Include file paths for images as attribute.\n",
    "        train_dataset.file_paths = image_paths_train\n",
    "        val_dataset.file_paths = image_paths_val\n",
    "        dataset = [train_dataset, val_dataset]\n",
    "    else:\n",
    "        image_paths, labels = dataset_utils.get_training_or_validation_split(\n",
    "            image_paths, labels, validation_split, subset\n",
    "        )\n",
    "        if not image_paths:\n",
    "            raise ValueError(\n",
    "                f\"No images found in directory {directory}. \"\n",
    "                f\"Allowed formats: {ALLOWLIST_FORMATS}\"\n",
    "            )\n",
    "\n",
    "        dataset = paths_and_labels_to_dataset(\n",
    "            image_paths=image_paths,\n",
    "            image_size=image_size,\n",
    "            num_channels=num_channels,\n",
    "            labels=labels,\n",
    "            label_mode=label_mode,\n",
    "            num_classes=len(class_names),\n",
    "            interpolation=interpolation,\n",
    "            crop_to_aspect_ratio=crop_to_aspect_ratio,\n",
    "        )\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        if batch_size is not None:\n",
    "            if shuffle:\n",
    "                # Shuffle locally at each iteration\n",
    "                dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n",
    "            dataset = dataset.batch(batch_size)\n",
    "        else:\n",
    "            if shuffle:\n",
    "                dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n",
    "\n",
    "        # Users may need to reference `class_names`.\n",
    "        dataset.class_names = class_names\n",
    "        # Include file paths for images as attribute.\n",
    "        dataset.file_paths = image_paths\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def paths_and_labels_to_dataset(\n",
    "    image_paths,\n",
    "    image_size,\n",
    "    num_channels,\n",
    "    labels,\n",
    "    label_mode,\n",
    "    num_classes,\n",
    "    interpolation,\n",
    "    crop_to_aspect_ratio=False,\n",
    "):\n",
    "    \"\"\"Constructs a dataset of images and labels.\"\"\"\n",
    "    # TODO(fchollet): consider making num_parallel_calls settable\n",
    "    #print(image_paths)\n",
    "    print(\"ASDASD\")\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    print(image_paths)\n",
    "    print(path_ds)\n",
    "    args = (image_size, num_channels)\n",
    "    img_ds = path_ds.map(\n",
    "        lambda x: load_image(x, *args), num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    print(img_ds)\n",
    "    print(img_ds)\n",
    "    if label_mode:\n",
    "        label_ds = dataset_utils.labels_to_dataset(\n",
    "            labels, label_mode, num_classes\n",
    "        )\n",
    "        img_ds = tf.data.Dataset.zip((img_ds, label_ds))\n",
    "    return img_ds\n",
    "\n",
    "\n",
    "def load_image(\n",
    "    path, image_size, num_channels ):\n",
    "    \"\"\"Load an image from a path and resize it.\"\"\"\n",
    "    print(path, image_size, num_channels)\n",
    "    img = tf.io.read_file(path)\n",
    "    #print(tf.io.decode_raw(img, tf.double))\n",
    "    #np.load(path)\n",
    "\n",
    "    \n",
    "    return tf.zeros(5)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    img = tf.image.decode_image(\n",
    "        img, channels=num_channels, expand_animations=False\n",
    "    )\n",
    "    if crop_to_aspect_ratio:\n",
    "        img = image_utils.smart_resize(\n",
    "            img, image_size, interpolation=interpolation\n",
    "        )\n",
    "    else:\n",
    "        img = tf.image.resize(img, image_size, method=interpolation)\n",
    "    img.set_shape((image_size[0], image_size[1], num_channels))\n",
    "    return img\n",
    "    \"\"\"\n",
    "\n",
    "ds = image_dataset_from_directory(\"dataset\", image_size=(125, 125))\n",
    "\n",
    "for x,y in ds:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 5)\n",
      "(32, 5)\n",
      "(32, 5)\n",
      "(6, 5)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets.folder import DatasetFolder\n",
    "\n",
    "def load_npy(path : str) -> torch.Tensor:\n",
    "    return torch.from_numpy(np.load(path))\n",
    "\n",
    "ds = DatasetFolder(\"dataset\", extensions=[\".npy\"], loader=load_npy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 125, 125])\n"
     ]
    }
   ],
   "source": [
    "for x, y in ds:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
